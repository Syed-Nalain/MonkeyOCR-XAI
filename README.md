# ðŸ” Explainable AI for MonkeyOCR: 
## Making OCR Decisions Transparent  

MonkeyOCR is a powerful OCR engine, but it has always acted as a **black box** â€” we knew *what* text it recognized but not *why*.  
This project introduces a **comprehensive Explainable AI (XAI) framework** for MonkeyOCR using **LIME** and **SHAP**, making its decisions transparent and interpretable.  

---

## ðŸš€ What's Happening  

- **Problem:** OCR works well but provides no explanation of decisions.  
- **Solution:** Implemented **OCR-aware LIME** and **OCR-specific SHAP** explanations.  
- **Impact:** Users can now see *why* text is recognized (or misrecognized).  

---

## ðŸ›  How It Works  

### ðŸŸ¢ OCR-Aware LIME Implementation  
Instead of generic LIME, I created a **custom OCR-specific approach**:  

1. **Smart Image Segmentation**  
   - ðŸ”¹ **SLIC Superpixels** â†’ coherent text regions  
   - ðŸ”¹ **Sobel Edge Detection** â†’ character boundaries  
   - ðŸ”¹ **Morphological Processing** â†’ connect broken characters  
   - âœ… Produces **26 meaningful segments** (not random grids)  

2. **OCR-Focused Prediction Function**  
   Evaluates regions using OCR-specific metrics:  
   - Text density  
   - Edge density  
   - Contrast levels  
   - Local binary patterns  
   - Brightness distribution  
   - Horizontal/vertical projections  

3. **LIME Process**  
   - Segment image â†’ perturb regions â†’ re-run OCR â†’ measure confidence drop  
   - Importance = `(Original - Modified) / Original`  
   - **Positive scores** â†’ crucial text regions  
   - **Negative scores** â†’ background/non-text noise  

---

### ðŸ”µ SHAP with OCR-Specific Features  
I engineered **8 OCR features** to measure contribution:  

- **Text Features**: Text density (25%), edge density (20%), dark regions (5%)  
- **Image Quality**: Contrast (15%), brightness mean (10%), brightness std (15%)  
- **Structure**: Uniformity (5%), bright regions (5%)  

**Computation Steps:**  
- Build baseline (median OCR doc features)  
- Compare current doc against baseline  
- Use Shapley values to assign fair contributions  

**Results:**  
- âœ… Text Density (+0.15) â†’ strongest positive driver  
- âœ… Brightness Mean (+0.08) â†’ good lighting improves OCR  

---

## ðŸ“Š Key Insights & Impact  

- ðŸ”Ž **94.14% faithfulness** â†’ explanations accurately match model behavior  
- ðŸ“ˆ Preprocessing (noise/background removal) improves OCR by ~15%  
- ðŸ›  Helps predict **OCR failures** before they happen  
- âœ… Increases **trust, transparency, debugging power**  

---

## ðŸ“‚ Project Structure  
â”œâ”€â”€ ðŸ“ Data Files
â”‚ â”œâ”€â”€ lime_fixed_analysis_data.json
â”‚ â”œâ”€â”€ shap_analysis_data.json
â”‚ â””â”€â”€ combined_analysis_data.json
â”œâ”€â”€ ðŸ“ Reports
â”‚ â””â”€â”€ comprehensive_ocr_xai_report.md


---

## âš™ï¸ Advanced Configuration  (optional)

You can adjust parameters for LIME & SHAP inside the code:  


### ðŸš€ Large Image Optimization (>2MB)  
- Images auto-resized to **600px max**  
- Use quick mode for speed  
- Preprocess manually if needed  

### ðŸ“‘ Complex Documents  
- Use specific task types (`text`, `formula`, `table`)  
- Increase LIME samples for reliable results  

---



